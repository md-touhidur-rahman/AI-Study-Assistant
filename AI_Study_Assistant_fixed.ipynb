{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FgtUBYg_YTCk",
    "outputId": "7d977494-f044-4934-ed0f-f0c724ab301b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m117.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.3/175.3 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip -q install pymupdf python-pptx pillow transformers sentence-transformers scikit-learn tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 706,
     "referenced_widgets": [
      "bd6b97825f184f95a003c598611357f9",
      "49e9af441e2e4f36a78997f3d00ef7cb",
      "2af4c9fb206541218fe2877bb299ea28",
      "2f2cdb49cc9649cc883c22f2353cb69a",
      "17852ece0e7b45a59ce4528e1d5062a0",
      "c0d78ffce01d418eb22ce5f2a94b2664",
      "17c62fb0c4d7447896a3db15f8f4b9dc",
      "fede8af37f61462a91cd973b9e13602f",
      "24695dfb46214d0a971ac47963a2c3e9",
      "1f2db1aef4cf4decb2f3d68f504d523d",
      "d7bbce4a626f43eb872974cdb52a361a",
      "58fc15d800454e17b9c72b0a4b1c7752",
      "e527f36d478d42559c32c672881c0a80",
      "ed1515a3f3944c419019c5760ec2167d",
      "0ab70980271d496499845f7a87eaee29",
      "140170f5cf354941b28b559963598d2c",
      "e4ea00abed6349dbb8116a16a3abb282",
      "c08e746a153f477d9fadc748d950ac75",
      "5e707449916c438ca6e668b624db7f03",
      "7ce1b87d4ce74a4d86d6dbe5ac9f4680",
      "f538a7c652164ca8a1037b7e654bb06b",
      "da5f6af55cb04e7f81cc231c1c752a87",
      "d4f8b72e03214cfaab1b97d2fd97b642",
      "078c1d4207624f919b7b2a8c3336cd69",
      "04b0d02186cc494bbd212d856e3d0d6b",
      "ee7fa20cd98d4595b883cfdf498f4bfb",
      "7d35f661a6784dd4843b1d23bc4bbcb7",
      "49d0415c44174575b7b04af3984cb291",
      "b36a785082e547f7b6d651409cd689a8",
      "b04f10620aaa4bb991b84b21b810333b",
      "e556891e81d44884bb1d9bc352a26326",
      "d48169b3b48a493aaab78b4741087b81",
      "015722be623d47d5b088bc80d0f4f2b8",
      "75e9b6916f9f4eb9925dbe9cb6ed8b75",
      "6240d4eb44ca480286f47d453e0ab16c",
      "1e96fb49114946f9b21c512579693462",
      "b3154a20ad534363be2552b77a4627a7",
      "a12022b233d34d6694e32d19ffda2784",
      "2e75f2bdb4c74c4ab0ac56fde0dd5d45",
      "e913062c83ce4aecaca61bb25ebb09a7",
      "f2b60e52d6d94b85b0b26eb1ad27c2fc",
      "85fffd15029c449faf117abdb5632d0c",
      "e1f04706e8bb438cac91f48e2e9e6830",
      "0678b064bc4d4e5e82c01abc9fbe0422",
      "dd0a46b56b994765b6a54dc6be5fc4c2",
      "e7112a3e7ecf49eda9e2ef0a40a6d1f8",
      "19fcc1391b8d44edaf7e0b5352263bc0",
      "9991f37617b241aca5212137573de456",
      "22bb2ec686ee4afeb83fad977d925df7",
      "8e5cabdaa9f247c29985e6c445aa8a35",
      "69ed32ef637a42fea797b45385baa491",
      "4085e08ec150493eb0373b8100be5414",
      "872fd2415b2b4830b43625cec95115d5",
      "d1f98eac33e44efa8fe3b55aa905e730",
      "cd46faa39ed941b883e5549d9e3eb52f",
      "357fb6ae41424779aab884e5fc86a01f",
      "09462aeb4029496cbbfdb22ddf0303cd",
      "063039a709eb4a8594e62c9bc7d440cb",
      "6cdbdbce1faa44e7beac03f8d178fb3f",
      "ed0898e1fd5246968339ba2cd4227c43",
      "aa6229a59a2d440d90c1604e56c0f31b",
      "d6a0c24ff7f548d2b7adfb4a0118d674",
      "28ce1c59ffda42d895abc9e7abf7e0a1",
      "f3b2f5ab52e94fc6be76baaf9568293a",
      "65a975271e9848f3b656f471e4528043",
      "2d1f37257972497f99990a8d2e16bfcf",
      "7247a9c031914acd8a205c206e8a1e51",
      "ca2dcd793c3648d98eb65c19c12edadb",
      "b36dc02b7b0a42eba7f3d593d8500d76",
      "58f278fb35dd4582aab9900235661934",
      "4ab6a00128114bd6898e837844a14a88",
      "89585b49062e4ce2b56fc75eaa4c815c",
      "543bafd4bf9240ce843c403a267c2a31",
      "bf0d7777584f41cfb6fb5513695ea14b",
      "cff42d8256704ac4bdcd6a7591f577d9",
      "cf91fc34a4264cb58aefd94cfb732a1f",
      "7da75966f70d480a98823e8cad580cce",
      "59d0456277b64b67b1a70ff2f3687f24",
      "b3381c269a8c4dd4ac0c33f6ecd24ff6",
      "91ee3f019d704cb99f4d6f74745f12d8",
      "ad8605def1f34594a707a06e6b2b468b",
      "fb0ce22c0dd140d89b5718972b5d8fba",
      "4ed51b9009c14f85973b9e2f278d226a",
      "c0ec7c9586ce4d828bf4e52fbd0a60b5",
      "ccf9447e0c5a42a3967e0168250c716b",
      "c4e5753803604eae80dd201996457ff9",
      "cbfa1b58a9344d74ad66ec17c25dffdb",
      "f956a953f27545a3bc21e03236087c5c",
      "3767c9d66fe547e0ae16c2beec9f9928",
      "a67ef20632f747ebadc49b8dcdaa4f3c",
      "b26632055914461492e224d162e2b373",
      "33e8bad6bbde49b1b3161b4bec73b8c6",
      "a91f3295df9945829ac9fbbe55d59595",
      "cd1c3f7cf4b84f94a5b80b947d3de304",
      "2620a2861bcb4945896c9c4e0e9dbf51",
      "b65b5dfd5b124a1d90cadd7c7db957bf",
      "4a813607786246058c5f699844604b67",
      "541e74bf7c7044eab3b810e81544ae15",
      "1bea090b6cc344e7aa90e1ed716152c5",
      "8fb782f64b344c0c9fd220fd058d1866",
      "2f4d0388bf884359b5d61f3b6d4151ef",
      "685cc450a68941a08d11f3f2492bfe82",
      "c66ff2040ea34537bad70f258ff5c0fe",
      "c04dc2b5e7184c83add75d37ccd39fe1",
      "445cc3313ab34085a082962aabb0326a",
      "fd097c255f6941e2b08900d76f802d63",
      "dbacd4117e784268bfc532481d42578a",
      "11c7a22082054a1180146bb01914e12a",
      "bbcdc7bfb3c14d41925654246872f958",
      "30662b82dd674087857ea3e771f38618",
      "2ff7a319bfd647cfaf39eab4561a4987",
      "55a492ef998e43258d955b78305edb64",
      "f4990874bf5e4c8997a9f6dd289a65ec",
      "cd0fd8701d7e4458aee86e3f1b877dc5",
      "42c3c2614a384035955d05fbe4ad6f18",
      "b4bd5d6ddde94420aa8f5326dcf4a843",
      "ee56f08c5ae5470ca7820a5ea34ba03d",
      "e88ec799b25c4ba2aa61158d44ae4fd7",
      "e2fe856ef40b485da76d1652839e7131",
      "6f28d4e9aefd433995681f3529eec56c",
      "8744dc5f918d4ce18223e40ba56d45cc",
      "2e764d9298f94bf4957c6063e8196821",
      "02f5960adff842839678213b32e8aeab",
      "5a1cf413564241a096c3a6961163d813",
      "2babd596ce2649a280f8e6285f43a556",
      "694b884924174aad8adad24488c6c56d",
      "7812bdfa6a98458e901232b119cf2222",
      "8b24405416e04ebcb7617c18831d5d28",
      "a071b234cb7a4bda8ac533392a527541",
      "d3d8019c03044f189a4aa5fa8fb3c05a",
      "90d676f05eb0402da43e3d348979e728",
      "610f34d8811043debe3540b3ade3cf70",
      "4a89763bbb634b43be4d5fa29b8158e6",
      "211a393a48b24480b8525e56476bb623",
      "4022b9a71f5d434abebd4ea73b1ede88",
      "98f51963b8b14e5292436a9735f026a9",
      "4048f083dec648c893060da2fcd0e30a",
      "10013f586d1f47508f4ab6acdc1fd2b5",
      "5c49fb8fdfd24d6ba0c903f375a77b9b",
      "3c06c6f9aea84685bfcdc3b3b9beb3fb",
      "8f5a0a30e4884dc0bc480461ef039a50",
      "9daf652bd9974f7184ea3ade6b936d81",
      "e3cc1fd71f434e57b0205e73a4614534",
      "1a7b806c7e3f427b91d828e49b1ee2c4",
      "25c5d97bdda648ff87d44392b1f3d8e8",
      "08eb04381b04458194176c0681dc1edf",
      "ac09fc76ac554072aa9e47e5052d2aec",
      "27995c8999f94021b566ba1521d5da6d",
      "0dcb92ce8d1f464f9bea60dbaea7f669",
      "be99ea1cc8c243d58ee10fff8e0b0e1c",
      "5e2511a6e70d4cec98053d1f53ae5c7e",
      "3a0dfe53f87c45179479748701b3fecc",
      "8cc157506510430cb21fa5d164ebf609",
      "a419dfe18e5e41e29b5156ed035a6f09",
      "67e0414cbb654968868e61b120a9085c",
      "3e6ed25bba8b41ce9e69d1f1636010aa",
      "91348888a67e4722a51f3e59cf88a937",
      "36ecbf7e07b643c4a53871461ae7062e",
      "cec9f4645899480687c7a435eab1c2c1",
      "9080260b9a0340bca1ebbabe2f2ae01a",
      "b0ad457e8f8f4580a9e2762ee445ecc5",
      "2395863c22954715849ed7a21eed3fb6",
      "54c3de48743c4e609dcbebe787cb02a5",
      "f894dd4e95634c038335b24b70a569a9",
      "63c430b90d4d4e45999394f87f1b74cf",
      "2bc2dada750445b6ac97769f4c8897b6",
      "a5057254af7a4e3493feea16022103bd",
      "3d506974177d4c08bae089eeb06b4dbc",
      "bfe7519a54764daebb9b594d43b3f8cb",
      "1be6c46906f64b94b5e635bedd5ee803",
      "19bf0a2c3fcb4f6a86501b6e6c303ed2",
      "f7741c8d8ef440fd8e9a6e3de9bcfe0b",
      "19a5e05b1a0e46bd8aec91139b9ae782",
      "65cee934ccf045699b27801649136983",
      "85bbad10a9e7496fbb4b11e5120aec20",
      "1ce69dab6c064f8fb2179623f1b68d0a",
      "3a833f33fc2740a6b9c3c890bafebfde",
      "2ed260a94899467697fe3cc36a38643d",
      "71edf4cdc5414be9b266b59e43928599",
      "86db1fac692c4ae09fa0effc2fee1711",
      "39db60f2e1124557904947eedd54c834",
      "a2145ad517f642feab89fdd4533cb56f",
      "5056e607065d4db59eb167131ea16a0b",
      "51c4f39469e04f98a1a5c0ba29269483",
      "1c10b255767f48cfb62f8e3c8c1156f6",
      "f9e00e30210f4372bc327423c6400104",
      "10f260e74dc14682915d14f8f300fd4d"
     ]
    },
    "id": "LSXA7IOzYT1_",
    "outputId": "dca9adf7-8748-4e47-9121-c99e34c60458"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd6b97825f184f95a003c598611357f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58fc15d800454e17b9c72b0a4b1c7752",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4f8b72e03214cfaab1b97d2fd97b642",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75e9b6916f9f4eb9925dbe9cb6ed8b75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd0a46b56b994765b6a54dc6be5fc4c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "357fb6ae41424779aab884e5fc86a01f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7247a9c031914acd8a205c206e8a1e51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59d0456277b64b67b1a70ff2f3687f24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3767c9d66fe547e0ae16c2beec9f9928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fb782f64b344c0c9fd220fd058d1866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ff7a319bfd647cfaf39eab4561a4987",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e764d9298f94bf4957c6063e8196821",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a89763bbb634b43be4d5fa29b8158e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a7b806c7e3f427b91d828e49b1ee2c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67e0414cbb654968868e61b120a9085c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bc2dada750445b6ac97769f4c8897b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a833f33fc2740a6b9c3c890bafebfde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os, io, json, csv\n",
    "from tqdm import tqdm\n",
    "import fitz  # PyMuPDF\n",
    "from pptx import Presentation\n",
    "from PIL import Image\n",
    "\n",
    "from transformers import pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# summarizer: BART\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\", device_map=\"auto\")\n",
    "\n",
    "# embeddings: MiniLM\n",
    "embedder = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QpQMnJDMYT48",
    "outputId": "0a4f703d-7a25-4d0b-b222-8126012a0f0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
      "debconf: falling back to frontend: Readline\n",
      "debconf: unable to initialize frontend: Readline\n",
      "debconf: (This frontend requires a controlling tty.)\n",
      "debconf: falling back to frontend: Teletype\n",
      "dpkg-preconfigure: unable to re-open stdin: \n",
      "Selecting previously unselected package tesseract-ocr-deu.\n",
      "(Reading database ... 126675 files and directories currently installed.)\n",
      "Preparing to unpack .../tesseract-ocr-deu_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
      "Unpacking tesseract-ocr-deu (1:4.00~git30-7274cfa-1.1) ...\n",
      "Setting up tesseract-ocr-deu (1:4.00~git30-7274cfa-1.1) ...\n"
     ]
    }
   ],
   "source": [
    "# OCR engine + German language pack\n",
    "!sudo apt-get -qq update && sudo apt-get -qq install -y tesseract-ocr tesseract-ocr-deu\n",
    "!pip -q install pytesseract\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "2Boyd4ubYT75"
   },
   "outputs": [],
   "source": [
    "import io, re\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "OCR_LANG = \"eng+deu\"      # supports English + German\n",
    "OCR_PSM = \"6\"             # treat as a block of text\n",
    "OCR_OEM = \"3\"             # default LSTM engine\n",
    "OCR_CONFIG = f\"--oem {OCR_OEM} --psm {OCR_PSM}\"\n",
    "\n",
    "def _clean_text(s: str) -> str:\n",
    "    s = re.sub(r\"[ \\t]+\", \" \", s)\n",
    "    s = re.sub(r\"\\n{3,}\", \"\\n\\n\", s)\n",
    "    return s.strip()\n",
    "\n",
    "def _ocr_pil(img: Image.Image) -> str:\n",
    "    return _clean_text(pytesseract.image_to_string(img, lang=OCR_LANG, config=OCR_CONFIG))\n",
    "\n",
    "def _pdf_page_to_image(page, dpi=300) -> Image.Image:\n",
    "    pix = page.get_pixmap(dpi=dpi)\n",
    "    return Image.open(io.BytesIO(pix.tobytes(\"png\"))).convert(\"RGB\")\n",
    "\n",
    "def extract_pdf_text(path, ocr=True, min_chars_no_ocr=25, dpi=300):\n",
    "    import fitz\n",
    "    doc = fitz.open(path)\n",
    "    slides, ocr_count = [], 0\n",
    "    for i, page in enumerate(doc):\n",
    "        raw = page.get_text().strip()\n",
    "        used_ocr = False\n",
    "        image_only = False\n",
    "        if (not raw or len(raw) < min_chars_no_ocr) and ocr:\n",
    "            img = _pdf_page_to_image(page, dpi=dpi)\n",
    "            raw = _ocr_pil(img)\n",
    "            used_ocr = True\n",
    "            image_only = True\n",
    "            ocr_count += 1\n",
    "        slides.append({\n",
    "            \"index\": i,\n",
    "            \"text\": _clean_text(raw),\n",
    "            \"source\": \"pdf\",\n",
    "            \"ocr_used\": used_ocr,\n",
    "            \"image_only\": image_only\n",
    "        })\n",
    "    print(f\"OCR used on {ocr_count}/{len(slides)} PDF pages.\")\n",
    "    return slides\n",
    "\n",
    "def extract_pptx_text(path, ocr=True):\n",
    "    from pptx import Presentation\n",
    "    prs = Presentation(path)\n",
    "    slides, ocr_count = [], 0\n",
    "    for i, s in enumerate(prs.slides):\n",
    "        texts, images_ocr = [], []\n",
    "        has_picture = False\n",
    "        for shape in s.shapes:\n",
    "            if hasattr(shape, \"text\") and shape.text:\n",
    "                texts.append(shape.text)\n",
    "            # 13 == picture\n",
    "            if getattr(shape, \"shape_type\", None) == 13:\n",
    "                has_picture = True\n",
    "                if ocr:\n",
    "                    try:\n",
    "                        img = Image.open(io.BytesIO(shape.image.blob)).convert(\"RGB\")\n",
    "                        images_ocr.append(_ocr_pil(img))\n",
    "                    except Exception:\n",
    "                        pass\n",
    "        raw = _clean_text(\"\\n\".join(t for t in texts if t))\n",
    "        used_ocr = False\n",
    "        image_only = False\n",
    "        if ocr and (not raw or len(raw) < 25) and has_picture:\n",
    "            ocr_txt = _clean_text(\"\\n\".join(t for t in images_ocr if t))\n",
    "            if ocr_txt:\n",
    "                raw = (raw + \"\\n\" + ocr_txt).strip() if raw else ocr_txt\n",
    "                used_ocr = True\n",
    "                image_only = (len(_clean_text(\"\\n\".join(texts))) < 5)\n",
    "                ocr_count += 1\n",
    "        slides.append({\n",
    "            \"index\": i,\n",
    "            \"text\": raw,\n",
    "            \"source\": \"pptx\",\n",
    "            \"ocr_used\": used_ocr,\n",
    "            \"image_only\": image_only\n",
    "        })\n",
    "    print(f\"OCR used on {ocr_count}/{len(slides)} PPTX slides.\")\n",
    "    return slides\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "id": "3rQv3ju2YT-u",
    "outputId": "758d4cb0-a24e-4645-89b2-39d9feb306d1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-85871ad7-887b-423e-9f31-31e3cb1076cc\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-85871ad7-887b-423e-9f31-31e3cb1076cc\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 1.MLISP_Introduction.pdf to 1.MLISP_Introduction.pdf\n",
      " Uploaded: 1.MLISP_Introduction.pdf\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "up = files.upload()  # choose your PDF or PPTX\n",
    "file_path = list(up.keys())[0]\n",
    "print(\" Uploaded:\", file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7OYvjM4iYUBj",
    "outputId": "79269c7c-81f0-4813-dac8-97703ef64e3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCR used on 0/38 PDF pages.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(38, 0, 0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ext = extract_pdf_text if file_path.lower().endswith(\".pdf\") else extract_pptx_text\n",
    "slides = ext(file_path, ocr=True)\n",
    "len(slides), sum(s[\"ocr_used\"] for s in slides), sum(s[\"image_only\"] for s in slides)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "7f4yi6gjYUEe"
   },
   "outputs": [],
   "source": [
    "# Summarizer (multilingual: DE/EN)\n",
    "from transformers import pipeline\n",
    "try:\n",
    "    summarizer\n",
    "except NameError:\n",
    "    summarizer = pipeline(\n",
    "        \"summarization\",\n",
    "        model=\"csebuetnlp/mT5_multilingual_XLSum\",\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "\n",
    "# Embeddings (multilingual MiniLM)\n",
    "from sentence_transformers import SentenceTransformer\n",
    "try:\n",
    "    embedder\n",
    "except NameError:\n",
    "    embedder = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j33J273GYUHY",
    "outputId": "57c6fcd7-7a01-4028-d833-47851a860bad"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/38 [00:00<?, ?it/s]Your max_length is set to 160, but your input_length is only 74. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=37)\n",
      "  8%|▊         | 3/38 [00:39<07:46, 13.33s/it]Your max_length is set to 160, but your input_length is only 85. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=42)\n",
      " 11%|█         | 4/38 [00:50<06:55, 12.22s/it]Your max_length is set to 160, but your input_length is only 150. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=75)\n",
      " 13%|█▎        | 5/38 [01:02<06:49, 12.42s/it]Your max_length is set to 160, but your input_length is only 124. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=62)\n",
      " 47%|████▋     | 18/38 [03:55<04:22, 13.11s/it]Your max_length is set to 160, but your input_length is only 145. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=72)\n",
      " 92%|█████████▏| 35/38 [07:34<00:39, 13.23s/it]Your max_length is set to 160, but your input_length is only 108. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=54)\n",
      " 95%|█████████▍| 36/38 [07:47<00:25, 12.97s/it]Your max_length is set to 160, but your input_length is only 97. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=48)\n",
      "100%|██████████| 38/38 [08:00<00:00, 12.63s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'index': 0,\n",
       " 'text': 'Prof. Dr. Vasileios Belagiannis\\nChair of Multimedia Communications and Signal Processing\\nMachine Learning in Signal Processing\\nWinter Semester 2025/26\\n1. Introduction\\n14.10.2025',\n",
       " 'summary': 'Prof. Dr. Vasileios Belagiannis\\nChair of Multimedia Communications and Signal Processing\\nMachine Learning in Signal Processing\\nWinter Semester 2025/26\\n1. Introduction\\n14.10.2025',\n",
       " 'ocr_used': False,\n",
       " 'image_only': False,\n",
       " 'source': 'pdf'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def summarize_text(txt):\n",
    "    txt = (txt or \"\").strip()\n",
    "    if not txt or len(txt.split()) < 25:\n",
    "        return txt  # keep as-is for very short slides\n",
    "    out = summarizer(txt, max_length=160, min_length=60, do_sample=False)[0][\"summary_text\"]\n",
    "    return out.strip()\n",
    "\n",
    "slide_summaries = []\n",
    "for s in tqdm(slides):\n",
    "    summary = summarize_text(s[\"text\"])\n",
    "    slide_summaries.append({\n",
    "        \"index\": s[\"index\"],\n",
    "        \"text\": s[\"text\"],\n",
    "        \"summary\": summary,\n",
    "        \"ocr_used\": s.get(\"ocr_used\", False),\n",
    "        \"image_only\": s.get(\"image_only\", False),\n",
    "        \"source\": s.get(\"source\", \"pdf\")\n",
    "    })\n",
    "\n",
    "# quick peek\n",
    "slide_summaries[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n_Tsfb89YUKF",
    "outputId": "2fd48c17-3731-4455-c01a-57370e7c28db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extractive deck summary written to outputs/deck_summary.txt\n",
      "Machine Learning in Signal Processing Online reference: https://machinelearningmastery.com/analytical-vs-numerical-solutions-in-machine-learning/ By mohamed_hassan https://pixabay.com/de/vectors/machine-learning-bücher- algorithmus-6079971/ Chair of Multimedia Communications and Signal Processing Page 11 ***Not for sharing (Friedrich-Alexander-Universität Erlangen-Nürnberg)*** Machine Learning Milestones (Timeline) Machine Learning in Signal Processing 1805 • Least Squares 1812 •Bayes' Theorem 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, re, string, json, math\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 1) build source text from slides (preferred) or slide_summaries.json\n",
    "try:\n",
    "    _ = slides[0]\n",
    "    pages = [s.get(\"text\",\"\") for s in slides if s.get(\"text\")]\n",
    "except Exception:\n",
    "    with open(\"outputs/slide_summaries.json\",\"r\",encoding=\"utf-8\") as f:\n",
    "        _ss = json.load(f)\n",
    "    pages = [s.get(\"text\",\"\") for s in _ss if s.get(\"text\")]\n",
    "\n",
    "doc = \"\\n\".join(pages)\n",
    "\n",
    "# 2) sentence splitting (DE/EN friendly)\n",
    "sentences = re.split(r'(?<=[.!?])\\s+', doc)\n",
    "sentences = [s.strip() for s in sentences if len(s.strip().split()) >= 6]\n",
    "\n",
    "# 3) TF-IDF ranking\n",
    "stop = \"\"\"\n",
    "der die das ein eine und oder für von mit ohne zu auf an im in aus ist sind war waren sein auch sowie\n",
    "the a an and or for from with without into in on of to is are was were be been being this that these those it its by as at if then else when while not\n",
    "data using use based results method methods model models paper figure table slide page\n",
    "\"\"\".split()\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=stop, max_df=0.9, min_df=2, ngram_range=(1,2))\n",
    "X = vectorizer.fit_transform(sentences)\n",
    "scores = X.sum(axis=1).A.ravel()\n",
    "\n",
    "# 4) MMR selection for diversity\n",
    "def mmr_select(sentences, scores, X, max_words=260, lambda_div=0.7):\n",
    "    chosen = []\n",
    "    chosen_idx = []\n",
    "    remaining = set(range(len(sentences)))\n",
    "    current_len = 0\n",
    "    sim = cosine_similarity(X, X)\n",
    "    # pick best first\n",
    "    i0 = int(scores.argmax())\n",
    "    chosen.append(sentences[i0]); chosen_idx.append(i0)\n",
    "    remaining.remove(i0); current_len += len(sentences[i0].split())\n",
    "    # keep adding while under word budget\n",
    "    while remaining and current_len < max_words:\n",
    "        best_i, best_val = None, -1e9\n",
    "        for i in remaining:\n",
    "            relevance = scores[i]\n",
    "            diversity = 0.0 if not chosen_idx else max(sim[i, chosen_idx])\n",
    "            val = lambda_div*relevance - (1-lambda_div)*diversity\n",
    "            if val > best_val:\n",
    "                best_val, best_i = val, i\n",
    "        s = sentences[best_i]\n",
    "        if current_len + len(s.split()) > max_words + 40:  # small slack\n",
    "            remaining.remove(best_i); continue\n",
    "        chosen.append(s); chosen_idx.append(best_i); remaining.remove(best_i)\n",
    "        current_len += len(s.split())\n",
    "    # restore original document order\n",
    "    ord_idx = sorted(chosen_idx)\n",
    "    return \" \".join(sentences[i] for i in ord_idx)\n",
    "\n",
    "summary = mmr_select(sentences, scores, X, max_words=260, lambda_div=0.7)\n",
    "\n",
    "# 5) light cleanup\n",
    "summary = re.sub(r'\\s+', ' ', summary).strip()\n",
    "\n",
    "# 6) save\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "with open(\"outputs/deck_summary.txt\",\"w\",encoding=\"utf-8\") as f:\n",
    "    f.write(summary)\n",
    "\n",
    "print(\"Extractive deck summary written to outputs/deck_summary.txt\")\n",
    "print(summary[:500])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rHoP5t5NYUNB",
    "outputId": "f209a21c-444e-42f1-8e86-11f6bc9fee1f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'slide_index': 15,\n",
       "  'score': 0.5227386355400085,\n",
       "  'preview': 'Markov Chain (1913) is a stochastic/random process that is memory-less. A Markov chains is a system of states with transition probabilities between the states. Applications: finance, genetics, computer vision, machine learning.Online Demo: '},\n",
       " {'slide_index': 27,\n",
       "  'score': 0.39752787351608276,\n",
       "  'preview': 'Reinforcement Learning (1989) is modelled as a Markov decision. The goal is to learn a policy to maximize the expected cumulative reward. Oleg Klimov, Chair of Multimedia Communications and Signal Processing at the University of Erlangen-Nü'},\n",
       " {'slide_index': 37,\n",
       "  'score': 0.25981271266937256,\n",
       "  'preview': 'Chair of Multimedia Communications and Signal Processing\\nPage 38\\n***Not for sharing (Friedrich-Alexander-Universität Erlangen-Nürnberg)***\\nNext Lecture\\nBasics & Terminology.\\nMachine Learning in Signal Processing'},\n",
       " {'slide_index': 26,\n",
       "  'score': 0.2542617917060852,\n",
       "  'preview': 'Reinforcement Learning (1989) An agent performs a sequence of actions to maximize the cumulative reward. The agent does not know the actions in advance. Exploration and exploitation of known actions is necessary. Explore new actions to furt'},\n",
       " {'slide_index': 16,\n",
       "  'score': 0.25189101696014404,\n",
       "  'preview': 'Graphical models express conditionaldependencies between random variables. Undirected graphical models and Bayesian networks are common models in the literature. Chair of Multimedia Communications and Signal Processing \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0Page 1'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "try:\n",
    "    embedder\n",
    "except NameError:\n",
    "    embedder = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "\n",
    "corpus = [f\"Slide {s['index']}: {s['summary'] or s['text']}\" for s in slide_summaries]\n",
    "embs = embedder.encode(corpus, convert_to_numpy=True, normalize_embeddings=True)\n",
    "\n",
    "def search(query, top_k=5):\n",
    "    q = embedder.encode([query], convert_to_numpy=True, normalize_embeddings=True)\n",
    "    sims = (embs @ q.T).ravel()\n",
    "    top_idx = sims.argsort()[::-1][:top_k]\n",
    "    return [\n",
    "        {\n",
    "            \"slide_index\": slide_summaries[i][\"index\"],\n",
    "            \"score\": float(sims[i]),\n",
    "            \"preview\": (slide_summaries[i][\"summary\"] or slide_summaries[i][\"text\"])[:240]\n",
    "        }\n",
    "        for i in top_idx\n",
    "    ]\n",
    "\n",
    "search(\"Markow-Eigenschaft\")  # or any query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "id": "wCFs2lmMYr_q",
    "outputId": "c0fc249a-4fe4-44ee-fd50-1570f03ba69a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "repr_error": "Out of range float values are not JSON compliant: nan",
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-d5842037-a671-4e80-9b99-487998fa235f\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>ocr</th>\n",
       "      <th>image_only</th>\n",
       "      <th>preview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d5842037-a671-4e80-9b99-487998fa235f')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-d5842037-a671-4e80-9b99-487998fa235f button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-d5842037-a671-4e80-9b99-487998fa235f');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index, ocr, image_only, preview]\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame([\n",
    "    {\"index\": s[\"index\"], \"ocr\": s[\"ocr_used\"], \"image_only\": s[\"image_only\"],\n",
    "     \"preview\": s[\"text\"][:120].replace(\"\\n\",\" \")}\n",
    "    for s in slides\n",
    "])\n",
    "df[df[\"ocr\"] | df[\"image_only\"]].head(10)  # shows any OCR'd slides\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aWeX6fLNYsCu",
    "outputId": "f1ea32b3-f59c-4324-998f-24c01b52c193"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " mindmap.mmd written to outputs/. Paste it into https://mermaid.live to render.\n"
     ]
    }
   ],
   "source": [
    "import re, os\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "def top_keywords(text, k=3):\n",
    "    words = re.findall(r\"[A-Za-zÄÖÜäöüß][A-Za-zÄÖÜäöüß\\-]{2,}\", text or \"\")\n",
    "    stop = set(\"\"\"\n",
    "der die das ein eine und oder für von mit ohne zu auf an im in aus ist sind war waren sein auch sowie\n",
    "the a an and or for from with without into in on of to is are was were be been being this that these those it its by as at if then else when while not\n",
    "\"\"\".split())\n",
    "    words = [w.lower() for w in words if w.lower() not in stop]\n",
    "    return [w for w,_ in Counter(words).most_common(k)]\n",
    "\n",
    "kw_to_slides = defaultdict(list)\n",
    "for s in slide_summaries:\n",
    "    base = s[\"summary\"] or s[\"text\"]\n",
    "    for kw in top_keywords(base, k=3):\n",
    "        kw_to_slides[kw].append(s[\"index\"])\n",
    "\n",
    "# keep top ~12 keywords\n",
    "top_kws = [kw for kw,_ in Counter(kw_to_slides.keys()).most_common()]\n",
    "top_kws = list(kw_to_slides.keys())[:12]\n",
    "\n",
    "title = os.path.basename(file_path)\n",
    "lines = [\"mindmap\", f\"  root(({title}))\"]\n",
    "for kw in top_kws:\n",
    "    lines.append(f\"    {kw}({kw})\")\n",
    "    for idx in sorted(kw_to_slides[kw])[:6]:\n",
    "        lines.append(f\"      s{idx}([Slide {idx}])\")\n",
    "\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "with open(\"outputs/mindmap.mmd\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(lines))\n",
    "\n",
    "print(\" mindmap.mmd written to outputs/. Paste it into https://mermaid.live to render.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TegKI0hOcydx",
    "outputId": "01ca7390-2b17-4b24-89e8-a09dc256040a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flashcards.csv written to outputs/ — total cards: 99\n"
     ]
    }
   ],
   "source": [
    "import csv, re\n",
    "\n",
    "def split_points(text):\n",
    "    bullets = re.findall(r\"(?:^|\\n)[\\-\\•\\*]\\s*(.+)\", text or \"\")\n",
    "    if bullets:\n",
    "        return [b.strip() for b in bullets if len(b.strip()) > 3][:4]\n",
    "    sents = re.split(r\"(?<=[\\.\\!\\?])\\s+\", text or \"\")\n",
    "    return [s for s in sents if len(s.split()) >= 6][:3]\n",
    "\n",
    "def detect_de(text: str) -> bool:\n",
    "    t = (text or \"\").lower()\n",
    "    if any(c in t for c in \"äöüÄÖÜß\"): return True\n",
    "    de_hits = sum(w in t for w in [\"und\",\"der\",\"die\",\"das\",\"ist\",\"nicht\",\"ein\",\"eine\",\"oder\",\"auch\"])\n",
    "    en_hits = sum(w in t for w in [\"and\",\"the\",\"is\",\"are\",\"not\",\"or\",\"also\",\"a\",\"an\"])\n",
    "    return de_hits >= en_hits\n",
    "\n",
    "rows = []\n",
    "for s in slide_summaries:\n",
    "    base = s[\"summary\"] or s[\"text\"]\n",
    "    if not base:\n",
    "        continue\n",
    "    de = detect_de(base)\n",
    "    items = split_points(base)\n",
    "    if items:\n",
    "        for j, it in enumerate(items, 1):\n",
    "            q = (f\"Nenne einen Kerngedanken (Folie {s['index']}, Punkt {j}):\"\n",
    "                 if de else\n",
    "                 f\"Name one key idea (slide {s['index']}, point {j}):\")\n",
    "            rows.append([q, it, f\"ClassMind;{'DE' if de else 'EN'}\"])\n",
    "    else:\n",
    "        q = (f\"Was ist die Kernaussage von Folie {s['index']}?\"\n",
    "             if de else\n",
    "             f\"What is the main idea of slide {s['index']}?\")\n",
    "        rows.append([q, base, f\"ClassMind;{'DE' if de else 'EN'}\"])\n",
    "\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "with open(\"outputs/flashcards.csv\", \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "    w = csv.writer(f); w.writerow([\"Question\",\"Answer\",\"Tags\"]); w.writerows(rows)\n",
    "\n",
    "print(f\"flashcards.csv written to outputs/ — total cards: {len(rows)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ibH_jIiacyg0",
    "outputId": "69e0dc96-9764-4a58-e2c1-2a16d52edd82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " deck_summary.txt written to outputs/\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "try:\n",
    "    summarizer\n",
    "except NameError:\n",
    "    summarizer = pipeline(\"summarization\", model=\"csebuetnlp/mT5_multilingual_XLSum\", device=-1)\n",
    "\n",
    "def chunk_by_tokens(text, tokenizer, max_tokens=480):\n",
    "    enc = tokenizer(text, return_attention_mask=False, truncation=False)\n",
    "    ids = enc[\"input_ids\"]\n",
    "    return [tokenizer.decode(ids[i:i+max_tokens], skip_special_tokens=True)\n",
    "            for i in range(0, len(ids), max_tokens)]\n",
    "\n",
    "def summarize_long_text(text, target_max=260, target_min=160, max_input_tokens=480):\n",
    "    tok = summarizer.tokenizer\n",
    "    if not text.strip():\n",
    "        return \"\"\n",
    "    parts = chunk_by_tokens(text, tok, max_tokens=max_input_tokens)\n",
    "    partial = [summarizer(p, max_length=160, min_length=60, do_sample=False, truncation=False)[0][\"summary_text\"] for p in parts]\n",
    "    merged = \"\\n\".join(partial)\n",
    "    final = summarizer(merged, max_length=target_max, min_length=target_min, do_sample=False, truncation=False)[0][\"summary_text\"]\n",
    "    return final.strip()\n",
    "\n",
    "full_text = \"\\n\\n\".join(s[\"text\"] for s in slides if s[\"text\"])\n",
    "deck_summary = summarize_long_text(full_text)\n",
    "\n",
    "with open(\"outputs/deck_summary.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(deck_summary)\n",
    "\n",
    "print(\" deck_summary.txt written to outputs/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hx3pefhBcyj3",
    "outputId": "e9d2ffb5-1912-48ef-848c-e54eb696f9c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEARNING: These slides contains a summary of the Markov Chain process - which makes it easier to understand.\n"
     ]
    }
   ],
   "source": [
    "# Build (or reuse) embeddings over slide texts/summaries\n",
    "slide_texts = [(s[\"index\"], (s[\"summary\"] or s[\"text\"])) for s in slide_summaries]\n",
    "corpus = [f\"Slide {idx}: {txt}\" for idx, txt in slide_texts]\n",
    "embs = embedder.encode(corpus, convert_to_numpy=True, normalize_embeddings=True)\n",
    "\n",
    "def retrieve(query, k=4):\n",
    "    q = embedder.encode([query], convert_to_numpy=True, normalize_embeddings=True)\n",
    "    sims = (embs @ q.T).ravel()\n",
    "    top = sims.argsort()[::-1][:k]\n",
    "    ctx = []\n",
    "    for i in top:\n",
    "        idx, txt = slide_texts[i]\n",
    "        ctx.append(f\"[Slide {idx}] {txt}\")\n",
    "    return ctx, sims[top].tolist()\n",
    "\n",
    "def answer(query):\n",
    "    ctx, scores = retrieve(query, k=4)\n",
    "    prompt = (\n",
    "        \"Beantworte die Frage kurz und präzise, basierend NUR auf dem Kontext.\\n\"\n",
    "        \"Wenn die Antwort nicht im Kontext steht, sage: 'Nicht im Material enthalten.'\\n\\n\"\n",
    "        \"KONTEXT:\\n\" + \"\\n\\n\".join(ctx) + \"\\n\\nFRAGE:\\n\" + query + \"\\n\\nANTWORT:\"\n",
    "    )\n",
    "    out = summarizer(prompt, max_length=120, min_length=30, do_sample=False)[0][\"summary_text\"]\n",
    "    return out.strip(), ctx, scores\n",
    "\n",
    "ans, ctx, scores = answer(\"Was ist die Markow-Eigenschaft?\")\n",
    "print(ans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kD-r3qcKcym4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 165
    },
    "id": "_ibZtYgrcyrH",
    "outputId": "a4ecb90d-b9b1-49e0-99f3-de6a7551adc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔼 Pick the problematic .ipynb file from your computer:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-77b02a4f-c3e5-4a49-9ebf-169c589b4db8\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-77b02a4f-c3e5-4a49-9ebf-169c589b4db8\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Untitled29.ipynb to Untitled29 (1).ipynb\n",
      "✅ Cleaned notebook created: Untitled29 (1)_clean.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-2641448564.py:42: MissingIDFieldWarning: Cell is missing an id field, this will become a hard error in future nbformat versions. You may want to use `normalize()` on your notebooks before validations (available since nbformat 5.1.4). Previous versions of nbformat are fixing this issue transparently, and will stop doing so in the future.\n",
      "  validate(nb)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_6ff7c740-7234-41a8-92ac-20de4e916d24\", \"Untitled29 (1)_clean.ipynb\", 62147)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fix a broken .ipynb so GitHub renders it (adds outputs: [], sets execution_count, strips widgets)\n",
    "!pip -q install nbformat==5.10.4\n",
    "import nbformat as nbf\n",
    "from nbformat.validator import validate\n",
    "from google.colab import files\n",
    "\n",
    "print(\"Pick the problematic .ipynb file from your computer:\")\n",
    "up = files.upload()\n",
    "name = list(up.keys())[0]\n",
    "raw = up[name].decode('utf-8')\n",
    "\n",
    "nb = nbf.reads(raw, as_version=4)\n",
    "\n",
    "# repo-level metadata (safe defaults)\n",
    "nb.metadata.pop('widgets', None)\n",
    "nb.metadata.setdefault('kernelspec', {'name': 'python3', 'display_name': 'Python 3'})\n",
    "nb.metadata.setdefault('language_info', {'name': 'python'})\n",
    "\n",
    "# ensure every code cell has required fields\n",
    "for c in nb.cells:\n",
    "    # remove stray widget metadata\n",
    "    if isinstance(c.get('metadata', {}), dict):\n",
    "        c.metadata.pop('widgets', None)\n",
    "\n",
    "    # source must be a string\n",
    "    if isinstance(c.get('source'), list):\n",
    "        c.source = ''.join(c.source)\n",
    "\n",
    "    if c.get('cell_type') == 'code':\n",
    "        if c.get('outputs') is None:\n",
    "            c['outputs'] = []\n",
    "        if 'outputs' not in c:\n",
    "            c['outputs'] = []\n",
    "        if 'execution_count' not in c:\n",
    "            c['execution_count'] = None\n",
    "\n",
    "# set nbformat headers\n",
    "nb.nbformat = 4\n",
    "nb.nbformat_minor = 5\n",
    "\n",
    "# validate schema\n",
    "validate(nb)\n",
    "\n",
    "clean_name = name.rsplit('.ipynb', 1)[0] + \"_clean.ipynb\"\n",
    "with open(clean_name, \"w\", encoding=\"utf-8\") as f:\n",
    "    nbf.write(nb, f)\n",
    "\n",
    "print(\" Cleaned notebook created:\", clean_name)\n",
    "files.download(clean_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "3U26T6Hfiz1X",
    "outputId": "6de6468e-df6d-4372-9def-ba2742503670"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ slide_summaries.json saved to outputs/\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_4ca4dce7-efd1-49e5-90fe-5c7c23326a87\", \"deck_summary.txt\", 599)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_1437d9af-e4ec-41c5-8fcf-e1bd6e4bd996\", \"slide_summaries.json\", 41769)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_a847ddc8-cf1a-4be3-bd4d-6be63ae4f990\", \"mindmap.mmd\", 1022)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_567e8efc-1e59-4b08-a99b-8540a5afd92e\", \"flashcards.csv\", 14507)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json, os\n",
    "\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "with open(\"outputs/slide_summaries.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(slide_summaries, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\" slide_summaries.json saved to outputs/\")\n",
    "\n",
    "from google.colab import files\n",
    "for p in [\"outputs/deck_summary.txt\",\n",
    "          \"outputs/slide_summaries.json\",\n",
    "          \"outputs/mindmap.mmd\",\n",
    "          \"outputs/flashcards.csv\"]:\n",
    "    files.download(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hgtT8olZo-Y_",
    "outputId": "5c98b2c7-1889-4b9b-9ff3-a03c7c6b9aec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned deck_summary.txt saved.\n",
      "Machine Learning in Signal Processing Online reference: By mohamed_hassan algorithmus-6079971/ Not for sharing (Friedrich-Alexander-Universität Erlangen-Nürnberg)*** Least Squares ( Adrien-Marie Legendre, 1805) - Find the best-fitting curve for a set of points, e.g. ications and Signal Processing ***Not for sharing (Friedrich-Alexander-Universität Erlangen-Nürnberg)*** Turing Test and (Cont.) - Originally called: imitation game. ications and Signal Processing ***Not for sharing (Friedrich-Alexan\n"
     ]
    }
   ],
   "source": [
    "import re, json, os\n",
    "\n",
    "path = \"outputs/deck_summary.txt\"\n",
    "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "    s = f.read()\n",
    "\n",
    "# remove URLs and image credits / licenses\n",
    "s = re.sub(r'https?://\\S+', ' ', s)\n",
    "s = re.sub(r'\\b(CC BY|Pixabay|Wikimedia|commons\\.wikimedia)\\b.*?(?=[A-Z]|\\Z)', ' ', s, flags=re.I|re.S)\n",
    "s = re.sub(r'\\bBy [A-Z][^,]{0,60},?\\s?', ' ', s)\n",
    "\n",
    "# remove watermark/headers like “Chair of … Page 12 ***Not for sharing***”\n",
    "s = re.sub(r'Chair of .*?Universität.*?\\*{3}.*?\\*{3}', ' ', s, flags=re.I)\n",
    "s = re.sub(r'\\bPage\\s*\\d+\\b', ' ', s, flags=re.I)\n",
    "\n",
    "# collapse bullets/stray glyphs and extra whitespace\n",
    "s = re.sub(r'•', ' - ', s)\n",
    "s = re.sub(r'\\s{2,}', ' ', s).strip()\n",
    "\n",
    "# de-duplicate repeated sentences\n",
    "sentences = [t.strip() for t in re.split(r'(?<=[.!?])\\s+', s) if t.strip()]\n",
    "seen, uniq = set(), []\n",
    "for t in sentences:\n",
    "    key = re.sub(r'\\W+', '', t.lower())\n",
    "    if key not in seen:\n",
    "        seen.add(key)\n",
    "        uniq.append(t)\n",
    "cleaned = ' '.join(uniq)\n",
    "\n",
    "with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(cleaned)\n",
    "\n",
    "print(\"Cleaned deck_summary.txt saved.\")\n",
    "print(cleaned[:500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "jE7DMQm1lI-3",
    "outputId": "dc5924cd-563f-48ab-ba43-9bff6d6f8140"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_8e2c20c7-746c-4ab5-8d8d-f73792214ece\", \"deck_summary.txt\", 1388)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from google.colab import files\n",
    "files.download(\"outputs/deck_summary.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-AlX-M_NlSbj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hP8TFZDRlShz"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
