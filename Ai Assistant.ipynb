{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "148873fb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FgtUBYg_YTCk",
    "outputId": "7d977494-f044-4934-ed0f-f0c724ab301b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m117.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.3/175.3 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip -q install pymupdf python-pptx pillow transformers sentence-transformers scikit-learn tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c078ef0a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 706,
     "referenced_widgets": [
      "bd6b97825f184f95a003c598611357f9",
      "49e9af441e2e4f36a78997f3d00ef7cb",
      "2af4c9fb206541218fe2877bb299ea28",
      "2f2cdb49cc9649cc883c22f2353cb69a",
      "17852ece0e7b45a59ce4528e1d5062a0",
      "c0d78ffce01d418eb22ce5f2a94b2664",
      "17c62fb0c4d7447896a3db15f8f4b9dc",
      "fede8af37f61462a91cd973b9e13602f",
      "24695dfb46214d0a971ac47963a2c3e9",
      "1f2db1aef4cf4decb2f3d68f504d523d",
      "d7bbce4a626f43eb872974cdb52a361a",
      "58fc15d800454e17b9c72b0a4b1c7752",
      "e527f36d478d42559c32c672881c0a80",
      "ed1515a3f3944c419019c5760ec2167d",
      "0ab70980271d496499845f7a87eaee29",
      "140170f5cf354941b28b559963598d2c",
      "e4ea00abed6349dbb8116a16a3abb282",
      "c08e746a153f477d9fadc748d950ac75",
      "5e707449916c438ca6e668b624db7f03",
      "7ce1b87d4ce74a4d86d6dbe5ac9f4680",
      "f538a7c652164ca8a1037b7e654bb06b",
      "da5f6af55cb04e7f81cc231c1c752a87",
      "d4f8b72e03214cfaab1b97d2fd97b642",
      "078c1d4207624f919b7b2a8c3336cd69",
      "04b0d02186cc494bbd212d856e3d0d6b",
      "ee7fa20cd98d4595b883cfdf498f4bfb",
      "7d35f661a6784dd4843b1d23bc4bbcb7",
      "49d0415c44174575b7b04af3984cb291",
      "b36a785082e547f7b6d651409cd689a8",
      "b04f10620aaa4bb991b84b21b810333b",
      "e556891e81d44884bb1d9bc352a26326",
      "d48169b3b48a493aaab78b4741087b81",
      "015722be623d47d5b088bc80d0f4f2b8",
      "75e9b6916f9f4eb9925dbe9cb6ed8b75",
      "6240d4eb44ca480286f47d453e0ab16c",
      "1e96fb49114946f9b21c512579693462",
      "b3154a20ad534363be2552b77a4627a7",
      "a12022b233d34d6694e32d19ffda2784",
      "2e75f2bdb4c74c4ab0ac56fde0dd5d45",
      "e913062c83ce4aecaca61bb25ebb09a7",
      "f2b60e52d6d94b85b0b26eb1ad27c2fc",
      "85fffd15029c449faf117abdb5632d0c",
      "e1f04706e8bb438cac91f48e2e9e6830",
      "0678b064bc4d4e5e82c01abc9fbe0422",
      "dd0a46b56b994765b6a54dc6be5fc4c2",
      "e7112a3e7ecf49eda9e2ef0a40a6d1f8",
      "19fcc1391b8d44edaf7e0b5352263bc0",
      "9991f37617b241aca5212137573de456",
      "22bb2ec686ee4afeb83fad977d925df7",
      "8e5cabdaa9f247c29985e6c445aa8a35",
      "69ed32ef637a42fea797b45385baa491",
      "4085e08ec150493eb0373b8100be5414",
      "872fd2415b2b4830b43625cec95115d5",
      "d1f98eac33e44efa8fe3b55aa905e730",
      "cd46faa39ed941b883e5549d9e3eb52f",
      "357fb6ae41424779aab884e5fc86a01f",
      "09462aeb4029496cbbfdb22ddf0303cd",
      "063039a709eb4a8594e62c9bc7d440cb",
      "6cdbdbce1faa44e7beac03f8d178fb3f",
      "ed0898e1fd5246968339ba2cd4227c43",
      "aa6229a59a2d440d90c1604e56c0f31b",
      "d6a0c24ff7f548d2b7adfb4a0118d674",
      "28ce1c59ffda42d895abc9e7abf7e0a1",
      "f3b2f5ab52e94fc6be76baaf9568293a",
      "65a975271e9848f3b656f471e4528043",
      "2d1f37257972497f99990a8d2e16bfcf",
      "7247a9c031914acd8a205c206e8a1e51",
      "ca2dcd793c3648d98eb65c19c12edadb",
      "b36dc02b7b0a42eba7f3d593d8500d76",
      "58f278fb35dd4582aab9900235661934",
      "4ab6a00128114bd6898e837844a14a88",
      "89585b49062e4ce2b56fc75eaa4c815c",
      "543bafd4bf9240ce843c403a267c2a31",
      "bf0d7777584f41cfb6fb5513695ea14b",
      "cff42d8256704ac4bdcd6a7591f577d9",
      "cf91fc34a4264cb58aefd94cfb732a1f",
      "7da75966f70d480a98823e8cad580cce",
      "59d0456277b64b67b1a70ff2f3687f24",
      "b3381c269a8c4dd4ac0c33f6ecd24ff6",
      "91ee3f019d704cb99f4d6f74745f12d8",
      "ad8605def1f34594a707a06e6b2b468b",
      "fb0ce22c0dd140d89b5718972b5d8fba",
      "4ed51b9009c14f85973b9e2f278d226a",
      "c0ec7c9586ce4d828bf4e52fbd0a60b5",
      "ccf9447e0c5a42a3967e0168250c716b",
      "c4e5753803604eae80dd201996457ff9",
      "cbfa1b58a9344d74ad66ec17c25dffdb",
      "f956a953f27545a3bc21e03236087c5c",
      "3767c9d66fe547e0ae16c2beec9f9928",
      "a67ef20632f747ebadc49b8dcdaa4f3c",
      "b26632055914461492e224d162e2b373",
      "33e8bad6bbde49b1b3161b4bec73b8c6",
      "a91f3295df9945829ac9fbbe55d59595",
      "cd1c3f7cf4b84f94a5b80b947d3de304",
      "2620a2861bcb4945896c9c4e0e9dbf51",
      "b65b5dfd5b124a1d90cadd7c7db957bf",
      "4a813607786246058c5f699844604b67",
      "541e74bf7c7044eab3b810e81544ae15",
      "1bea090b6cc344e7aa90e1ed716152c5",
      "8fb782f64b344c0c9fd220fd058d1866",
      "2f4d0388bf884359b5d61f3b6d4151ef",
      "685cc450a68941a08d11f3f2492bfe82",
      "c66ff2040ea34537bad70f258ff5c0fe",
      "c04dc2b5e7184c83add75d37ccd39fe1",
      "445cc3313ab34085a082962aabb0326a",
      "fd097c255f6941e2b08900d76f802d63",
      "dbacd4117e784268bfc532481d42578a",
      "11c7a22082054a1180146bb01914e12a",
      "bbcdc7bfb3c14d41925654246872f958",
      "30662b82dd674087857ea3e771f38618",
      "2ff7a319bfd647cfaf39eab4561a4987",
      "55a492ef998e43258d955b78305edb64",
      "f4990874bf5e4c8997a9f6dd289a65ec",
      "cd0fd8701d7e4458aee86e3f1b877dc5",
      "42c3c2614a384035955d05fbe4ad6f18",
      "b4bd5d6ddde94420aa8f5326dcf4a843",
      "ee56f08c5ae5470ca7820a5ea34ba03d",
      "e88ec799b25c4ba2aa61158d44ae4fd7",
      "e2fe856ef40b485da76d1652839e7131",
      "6f28d4e9aefd433995681f3529eec56c",
      "8744dc5f918d4ce18223e40ba56d45cc",
      "2e764d9298f94bf4957c6063e8196821",
      "02f5960adff842839678213b32e8aeab",
      "5a1cf413564241a096c3a6961163d813",
      "2babd596ce2649a280f8e6285f43a556",
      "694b884924174aad8adad24488c6c56d",
      "7812bdfa6a98458e901232b119cf2222",
      "8b24405416e04ebcb7617c18831d5d28",
      "a071b234cb7a4bda8ac533392a527541",
      "d3d8019c03044f189a4aa5fa8fb3c05a",
      "90d676f05eb0402da43e3d348979e728",
      "610f34d8811043debe3540b3ade3cf70",
      "4a89763bbb634b43be4d5fa29b8158e6",
      "211a393a48b24480b8525e56476bb623",
      "4022b9a71f5d434abebd4ea73b1ede88",
      "98f51963b8b14e5292436a9735f026a9",
      "4048f083dec648c893060da2fcd0e30a",
      "10013f586d1f47508f4ab6acdc1fd2b5",
      "5c49fb8fdfd24d6ba0c903f375a77b9b",
      "3c06c6f9aea84685bfcdc3b3b9beb3fb",
      "8f5a0a30e4884dc0bc480461ef039a50",
      "9daf652bd9974f7184ea3ade6b936d81",
      "e3cc1fd71f434e57b0205e73a4614534",
      "1a7b806c7e3f427b91d828e49b1ee2c4",
      "25c5d97bdda648ff87d44392b1f3d8e8",
      "08eb04381b04458194176c0681dc1edf",
      "ac09fc76ac554072aa9e47e5052d2aec",
      "27995c8999f94021b566ba1521d5da6d",
      "0dcb92ce8d1f464f9bea60dbaea7f669",
      "be99ea1cc8c243d58ee10fff8e0b0e1c",
      "5e2511a6e70d4cec98053d1f53ae5c7e",
      "3a0dfe53f87c45179479748701b3fecc",
      "8cc157506510430cb21fa5d164ebf609",
      "a419dfe18e5e41e29b5156ed035a6f09",
      "67e0414cbb654968868e61b120a9085c",
      "3e6ed25bba8b41ce9e69d1f1636010aa",
      "91348888a67e4722a51f3e59cf88a937",
      "36ecbf7e07b643c4a53871461ae7062e",
      "cec9f4645899480687c7a435eab1c2c1",
      "9080260b9a0340bca1ebbabe2f2ae01a",
      "b0ad457e8f8f4580a9e2762ee445ecc5",
      "2395863c22954715849ed7a21eed3fb6",
      "54c3de48743c4e609dcbebe787cb02a5",
      "f894dd4e95634c038335b24b70a569a9",
      "63c430b90d4d4e45999394f87f1b74cf",
      "2bc2dada750445b6ac97769f4c8897b6",
      "a5057254af7a4e3493feea16022103bd",
      "3d506974177d4c08bae089eeb06b4dbc",
      "bfe7519a54764daebb9b594d43b3f8cb",
      "1be6c46906f64b94b5e635bedd5ee803",
      "19bf0a2c3fcb4f6a86501b6e6c303ed2",
      "f7741c8d8ef440fd8e9a6e3de9bcfe0b",
      "19a5e05b1a0e46bd8aec91139b9ae782",
      "65cee934ccf045699b27801649136983",
      "85bbad10a9e7496fbb4b11e5120aec20",
      "1ce69dab6c064f8fb2179623f1b68d0a",
      "3a833f33fc2740a6b9c3c890bafebfde",
      "2ed260a94899467697fe3cc36a38643d",
      "71edf4cdc5414be9b266b59e43928599",
      "86db1fac692c4ae09fa0effc2fee1711",
      "39db60f2e1124557904947eedd54c834",
      "a2145ad517f642feab89fdd4533cb56f",
      "5056e607065d4db59eb167131ea16a0b",
      "51c4f39469e04f98a1a5c0ba29269483",
      "1c10b255767f48cfb62f8e3c8c1156f6",
      "f9e00e30210f4372bc327423c6400104",
      "10f260e74dc14682915d14f8f300fd4d"
     ]
    },
    "id": "LSXA7IOzYT1_",
    "outputId": "dca9adf7-8748-4e47-9121-c99e34c60458"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd6b97825f184f95a003c598611357f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58fc15d800454e17b9c72b0a4b1c7752",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4f8b72e03214cfaab1b97d2fd97b642",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75e9b6916f9f4eb9925dbe9cb6ed8b75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd0a46b56b994765b6a54dc6be5fc4c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "357fb6ae41424779aab884e5fc86a01f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7247a9c031914acd8a205c206e8a1e51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59d0456277b64b67b1a70ff2f3687f24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3767c9d66fe547e0ae16c2beec9f9928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fb782f64b344c0c9fd220fd058d1866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ff7a319bfd647cfaf39eab4561a4987",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e764d9298f94bf4957c6063e8196821",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a89763bbb634b43be4d5fa29b8158e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a7b806c7e3f427b91d828e49b1ee2c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67e0414cbb654968868e61b120a9085c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bc2dada750445b6ac97769f4c8897b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a833f33fc2740a6b9c3c890bafebfde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os, io, json, csv\n",
    "from tqdm import tqdm\n",
    "import fitz  # PyMuPDF\n",
    "from pptx import Presentation\n",
    "from PIL import Image\n",
    "\n",
    "from transformers import pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# summarizer: BART\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\", device_map=\"auto\")\n",
    "\n",
    "# embeddings: MiniLM\n",
    "embedder = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ad1bca2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QpQMnJDMYT48",
    "outputId": "0a4f703d-7a25-4d0b-b222-8126012a0f0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
      "debconf: falling back to frontend: Readline\n",
      "debconf: unable to initialize frontend: Readline\n",
      "debconf: (This frontend requires a controlling tty.)\n",
      "debconf: falling back to frontend: Teletype\n",
      "dpkg-preconfigure: unable to re-open stdin: \n",
      "Selecting previously unselected package tesseract-ocr-deu.\n",
      "(Reading database ... 126675 files and directories currently installed.)\n",
      "Preparing to unpack .../tesseract-ocr-deu_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
      "Unpacking tesseract-ocr-deu (1:4.00~git30-7274cfa-1.1) ...\n",
      "Setting up tesseract-ocr-deu (1:4.00~git30-7274cfa-1.1) ...\n"
     ]
    }
   ],
   "source": [
    "# OCR engine + German language pack\n",
    "!sudo apt-get -qq update && sudo apt-get -qq install -y tesseract-ocr tesseract-ocr-deu\n",
    "!pip -q install pytesseract\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17853785",
   "metadata": {
    "id": "2Boyd4ubYT75"
   },
   "outputs": [],
   "source": [
    "import io, re\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "OCR_LANG = \"eng+deu\"      # supports English + German\n",
    "OCR_PSM = \"6\"             # treat as a block of text\n",
    "OCR_OEM = \"3\"             # default LSTM engine\n",
    "OCR_CONFIG = f\"--oem {OCR_OEM} --psm {OCR_PSM}\"\n",
    "\n",
    "def _clean_text(s: str) -> str:\n",
    "    s = re.sub(r\"[ \\t]+\", \" \", s)\n",
    "    s = re.sub(r\"\\n{3,}\", \"\\n\\n\", s)\n",
    "    return s.strip()\n",
    "\n",
    "def _ocr_pil(img: Image.Image) -> str:\n",
    "    return _clean_text(pytesseract.image_to_string(img, lang=OCR_LANG, config=OCR_CONFIG))\n",
    "\n",
    "def _pdf_page_to_image(page, dpi=300) -> Image.Image:\n",
    "    pix = page.get_pixmap(dpi=dpi)\n",
    "    return Image.open(io.BytesIO(pix.tobytes(\"png\"))).convert(\"RGB\")\n",
    "\n",
    "def extract_pdf_text(path, ocr=True, min_chars_no_ocr=25, dpi=300):\n",
    "    import fitz\n",
    "    doc = fitz.open(path)\n",
    "    slides, ocr_count = [], 0\n",
    "    for i, page in enumerate(doc):\n",
    "        raw = page.get_text().strip()\n",
    "        used_ocr = False\n",
    "        image_only = False\n",
    "        if (not raw or len(raw) < min_chars_no_ocr) and ocr:\n",
    "            img = _pdf_page_to_image(page, dpi=dpi)\n",
    "            raw = _ocr_pil(img)\n",
    "            used_ocr = True\n",
    "            image_only = True\n",
    "            ocr_count += 1\n",
    "        slides.append({\n",
    "            \"index\": i,\n",
    "            \"text\": _clean_text(raw),\n",
    "            \"source\": \"pdf\",\n",
    "            \"ocr_used\": used_ocr,\n",
    "            \"image_only\": image_only\n",
    "        })\n",
    "    print(f\"OCR used on {ocr_count}/{len(slides)} PDF pages.\")\n",
    "    return slides\n",
    "\n",
    "def extract_pptx_text(path, ocr=True):\n",
    "    from pptx import Presentation\n",
    "    prs = Presentation(path)\n",
    "    slides, ocr_count = [], 0\n",
    "    for i, s in enumerate(prs.slides):\n",
    "        texts, images_ocr = [], []\n",
    "        has_picture = False\n",
    "        for shape in s.shapes:\n",
    "            if hasattr(shape, \"text\") and shape.text:\n",
    "                texts.append(shape.text)\n",
    "            # 13 == picture\n",
    "            if getattr(shape, \"shape_type\", None) == 13:\n",
    "                has_picture = True\n",
    "                if ocr:\n",
    "                    try:\n",
    "                        img = Image.open(io.BytesIO(shape.image.blob)).convert(\"RGB\")\n",
    "                        images_ocr.append(_ocr_pil(img))\n",
    "                    except Exception:\n",
    "                        pass\n",
    "        raw = _clean_text(\"\\n\".join(t for t in texts if t))\n",
    "        used_ocr = False\n",
    "        image_only = False\n",
    "        if ocr and (not raw or len(raw) < 25) and has_picture:\n",
    "            ocr_txt = _clean_text(\"\\n\".join(t for t in images_ocr if t))\n",
    "            if ocr_txt:\n",
    "                raw = (raw + \"\\n\" + ocr_txt).strip() if raw else ocr_txt\n",
    "                used_ocr = True\n",
    "                image_only = (len(_clean_text(\"\\n\".join(texts))) < 5)\n",
    "                ocr_count += 1\n",
    "        slides.append({\n",
    "            \"index\": i,\n",
    "            \"text\": raw,\n",
    "            \"source\": \"pptx\",\n",
    "            \"ocr_used\": used_ocr,\n",
    "            \"image_only\": image_only\n",
    "        })\n",
    "    print(f\"OCR used on {ocr_count}/{len(slides)} PPTX slides.\")\n",
    "    return slides\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e63ad84",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "id": "3rQv3ju2YT-u",
    "outputId": "758d4cb0-a24e-4645-89b2-39d9feb306d1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-85871ad7-887b-423e-9f31-31e3cb1076cc\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-85871ad7-887b-423e-9f31-31e3cb1076cc\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 1.MLISP_Introduction.pdf to 1.MLISP_Introduction.pdf\n",
      " Uploaded: 1.MLISP_Introduction.pdf\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "up = files.upload()  # choose your PDF or PPTX\n",
    "file_path = list(up.keys())[0]\n",
    "print(\" Uploaded:\", file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a65d666f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7OYvjM4iYUBj",
    "outputId": "79269c7c-81f0-4813-dac8-97703ef64e3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCR used on 0/38 PDF pages.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(38, 0, 0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ext = extract_pdf_text if file_path.lower().endswith(\".pdf\") else extract_pptx_text\n",
    "slides = ext(file_path, ocr=True)\n",
    "len(slides), sum(s[\"ocr_used\"] for s in slides), sum(s[\"image_only\"] for s in slides)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b768527",
   "metadata": {
    "id": "7f4yi6gjYUEe"
   },
   "outputs": [],
   "source": [
    "# Summarizer (multilingual: DE/EN)\n",
    "from transformers import pipeline\n",
    "try:\n",
    "    summarizer\n",
    "except NameError:\n",
    "    summarizer = pipeline(\n",
    "        \"summarization\",\n",
    "        model=\"csebuetnlp/mT5_multilingual_XLSum\",\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "\n",
    "# Embeddings (multilingual MiniLM)\n",
    "from sentence_transformers import SentenceTransformer\n",
    "try:\n",
    "    embedder\n",
    "except NameError:\n",
    "    embedder = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14040d5e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j33J273GYUHY",
    "outputId": "57c6fcd7-7a01-4028-d833-47851a860bad"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/38 [00:00<?, ?it/s]Your max_length is set to 160, but your input_length is only 74. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=37)\n",
      "  8%|▊         | 3/38 [00:39<07:46, 13.33s/it]Your max_length is set to 160, but your input_length is only 85. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=42)\n",
      " 11%|█         | 4/38 [00:50<06:55, 12.22s/it]Your max_length is set to 160, but your input_length is only 150. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=75)\n",
      " 13%|█▎        | 5/38 [01:02<06:49, 12.42s/it]Your max_length is set to 160, but your input_length is only 124. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=62)\n",
      " 47%|████▋     | 18/38 [03:55<04:22, 13.11s/it]Your max_length is set to 160, but your input_length is only 145. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=72)\n",
      " 92%|█████████▏| 35/38 [07:34<00:39, 13.23s/it]Your max_length is set to 160, but your input_length is only 108. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=54)\n",
      " 95%|█████████▍| 36/38 [07:47<00:25, 12.97s/it]Your max_length is set to 160, but your input_length is only 97. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=48)\n",
      "100%|██████████| 38/38 [08:00<00:00, 12.63s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'index': 0,\n",
       " 'text': 'Prof. Dr. Vasileios Belagiannis\\nChair of Multimedia Communications and Signal Processing\\nMachine Learning in Signal Processing\\nWinter Semester 2025/26\\n1. Introduction\\n14.10.2025',\n",
       " 'summary': 'Prof. Dr. Vasileios Belagiannis\\nChair of Multimedia Communications and Signal Processing\\nMachine Learning in Signal Processing\\nWinter Semester 2025/26\\n1. Introduction\\n14.10.2025',\n",
       " 'ocr_used': False,\n",
       " 'image_only': False,\n",
       " 'source': 'pdf'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def summarize_text(txt):\n",
    "    txt = (txt or \"\").strip()\n",
    "    if not txt or len(txt.split()) < 25:\n",
    "        return txt  # keep as-is for very short slides\n",
    "    out = summarizer(txt, max_length=160, min_length=60, do_sample=False)[0][\"summary_text\"]\n",
    "    return out.strip()\n",
    "\n",
    "slide_summaries = []\n",
    "for s in tqdm(slides):\n",
    "    summary = summarize_text(s[\"text\"])\n",
    "    slide_summaries.append({\n",
    "        \"index\": s[\"index\"],\n",
    "        \"text\": s[\"text\"],\n",
    "        \"summary\": summary,\n",
    "        \"ocr_used\": s.get(\"ocr_used\", False),\n",
    "        \"image_only\": s.get(\"image_only\", False),\n",
    "        \"source\": s.get(\"source\", \"pdf\")\n",
    "    })\n",
    "\n",
    "# quick peek\n",
    "slide_summaries[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eba74846",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318,
     "referenced_widgets": [
      "b4992862cf324b9e836da8321ec45366",
      "76553f7170c042b59a286bd77c9d8c3b",
      "5c252539850f4eba8244f16178893f4a",
      "a541a582985c43d79488dd6b6a43b66e",
      "df9a67bd1f2d4e64bbcaaa5504973e4f",
      "eb574271fa5f46d3a4bde99ac44ed753",
      "cf6c1d21e60944fbbcfde57f8e6532f8",
      "ffbb6c4917154cef847bd92f5937730a",
      "7b84e0a515fd4820aabca08c3e77cd69",
      "d8860e669a1c4a3eab474558b6e1117b",
      "19c5a796f8ba4bfe93cd93baee1ed337",
      "44f428e212b149a5a4be5bca320befa7",
      "b478425c3b6c4da681158baf83aadcf2",
      "5f1d9182d3e249b1acf5ce4ad9cde0a4",
      "eaab19f1382a4cfb98fe7246ce87343d",
      "a7c8569874bf4809b4d1df037841fb93",
      "1919ef244b704b568fa7e02dba31676d",
      "41161ef6c10844c7b7fbae59a1363638",
      "8a9e3e99ba9e48d19b05d120f7f63021",
      "748c73a6f9b44d34879a37d1da7e0674",
      "0382a08152934057bdcd7f106c0d015f",
      "17a4becd4dbc4e9b967c4ebae1b7d228",
      "71f84efdb93449b3a03141ee06924618",
      "633edd9710e04296b50c5ecf37a306d9",
      "984c675eeaef4ad28f9bb2a3302d734e",
      "8185590c7941433bad6969953aab401e",
      "37b0638c7e1345f8ad802ac0e8693a66",
      "2669417314e54ce8988c4cb10bf09812",
      "4be5dcaa19594efbbc0e1558c6338802",
      "74caed4d4eb345b48bf0be0caca9fef5",
      "45045a83778547e0a2c52ce46c323672",
      "41c077d2ab2f49f1b67e1758918d1783",
      "8df0c2911a2b40efb8ad9596b51f6b65",
      "6422ceb5a79240b1920f9c54b82d7fd4",
      "b4ab6ace8d8640bb85fef37a967e29b5",
      "0fb75d8ea59e40e5bb13d40b4e2db4ed",
      "182c5a6a20614ddab4b36d4f36830bf1",
      "fc48864efbac410d80e95cc393238939",
      "c7630a90463c47c8aa75c2bce9fc529e",
      "581b67df826a4c3992552ac2fc59f548",
      "1470c0c7461041958b814d502fac382f",
      "c4d149a13ced48fe8e16b86fb3a3fae6",
      "af9586e3db3d4edabe9af5a387f87dd4",
      "6324cdebd0b34ed88ca9d73a15ac7dd8",
      "01322a098cb14b758812749bfd158acd",
      "08b33a43b3f548d49d636dd83d1f9330",
      "f3a3b20ce6e94c83a382cc67e9c3dddc",
      "f604e4857d5b43f4baa62cdff8962989",
      "0eec1f4dcb6a42c29e5654cab2f8eba0",
      "f4fe4e96e9f246fd9940cfdf0935861a",
      "351fe7fd189e4f9795c75fcfeb0c8b2f",
      "1f63954a20c64c28851c80e63d1875a5",
      "bf2e362cf9994e8fbd3518a5cdd75b65",
      "36a9934d75c34eb9b5b2d472456497f5",
      "07f964685a26449197ddde347ff59013",
      "68a73296e15a494dbd333e2ce521e098",
      "d5f06a91cd7945549c8f7b5e8022b038",
      "e2c6304d05744ca6a089e82589b6e518",
      "da871734defb4d179621b66eca72d072",
      "e73224bde93e4f719a196cff1e7fcc44",
      "c295cdfd5ea94233a55744771065343f",
      "a50f9ac2d8ef447ebb1b192c2709a622",
      "b4b1a23c6b404e1fa102d40d341ea8c0",
      "73bef2b0872c4678a214a58e5d756615",
      "2ff38b8155d740da8763ad3b9ba1a003",
      "6b2e211f02924af2bcca1ae98b76ede0"
     ]
    },
    "id": "n_Tsfb89YUKF",
    "outputId": "3a7abf53-2339-4b7d-b7bc-bb7768b2d6a7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4992862cf324b9e836da8321ec45366",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/730 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44f428e212b149a5a4be5bca320befa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71f84efdb93449b3a03141ee06924618",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6422ceb5a79240b1920f9c54b82d7fd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/375 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01322a098cb14b758812749bfd158acd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/4.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68a73296e15a494dbd333e2ce521e098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/65.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "/usr/local/lib/python3.12/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This week's SWS exercises are being held at the University of Erlangen-Nürnberg in Germany. This is a series of letters from African journalists, scientists and academics explaining the key facts about the machine learning process and how they developed their algorithms to predict the spread of coronavirus across the UK. These are some of.. BBC News Arabic has been asked to find out what lessons h\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# CPU summarizer (stable)\n",
    "summarizer = pipeline(\n",
    "    \"summarization\",\n",
    "    model=\"csebuetnlp/mT5_multilingual_XLSum\",\n",
    "    device=-1  # CPU\n",
    ")\n",
    "\n",
    "def chunk_by_tokens(text, tokenizer, max_tokens=480):\n",
    "    enc = tokenizer(text, return_attention_mask=False, truncation=False)\n",
    "    ids = enc[\"input_ids\"]\n",
    "    chunks = []\n",
    "    for i in range(0, len(ids), max_tokens):\n",
    "        chunk_ids = ids[i:i+max_tokens]\n",
    "        chunks.append(tokenizer.decode(chunk_ids, skip_special_tokens=True))\n",
    "    return chunks\n",
    "\n",
    "def summarize_long_text(text, target_max=260, target_min=160, max_input_tokens=480):\n",
    "    tok = summarizer.tokenizer\n",
    "    if not text.strip():\n",
    "        return \"\"\n",
    "    pieces = chunk_by_tokens(text, tok, max_tokens=max_input_tokens)\n",
    "\n",
    "    partial = []\n",
    "    for p in pieces:\n",
    "        s = summarizer(p, max_length=160, min_length=60, do_sample=False, truncation=False)[0][\"summary_text\"]\n",
    "        partial.append(s)\n",
    "\n",
    "    merged = \"\\n\".join(partial)\n",
    "    final = summarizer(merged, max_length=target_max, min_length=target_min, do_sample=False, truncation=False)[0][\"summary_text\"]\n",
    "    return final.strip()\n",
    "\n",
    "# Build deck summary\n",
    "full_text = \"\\n\\n\".join(s[\"text\"] for s in slides if s[\"text\"])\n",
    "deck_summary = summarize_long_text(full_text, target_max=260, target_min=160, max_input_tokens=480)\n",
    "\n",
    "import os\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "with open(\"outputs/deck_summary.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(deck_summary)\n",
    "\n",
    "print(deck_summary[:400])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd82bf1c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rHoP5t5NYUNB",
    "outputId": "f209a21c-444e-42f1-8e86-11f6bc9fee1f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'slide_index': 15,\n",
       "  'score': 0.5227386355400085,\n",
       "  'preview': 'Markov Chain (1913) is a stochastic/random process that is memory-less. A Markov chains is a system of states with transition probabilities between the states. Applications: finance, genetics, computer vision, machine learning.Online Demo: '},\n",
       " {'slide_index': 27,\n",
       "  'score': 0.39752787351608276,\n",
       "  'preview': 'Reinforcement Learning (1989) is modelled as a Markov decision. The goal is to learn a policy to maximize the expected cumulative reward. Oleg Klimov, Chair of Multimedia Communications and Signal Processing at the University of Erlangen-Nü'},\n",
       " {'slide_index': 37,\n",
       "  'score': 0.25981271266937256,\n",
       "  'preview': 'Chair of Multimedia Communications and Signal Processing\\nPage 38\\n***Not for sharing (Friedrich-Alexander-Universität Erlangen-Nürnberg)***\\nNext Lecture\\nBasics & Terminology.\\nMachine Learning in Signal Processing'},\n",
       " {'slide_index': 26,\n",
       "  'score': 0.2542617917060852,\n",
       "  'preview': 'Reinforcement Learning (1989) An agent performs a sequence of actions to maximize the cumulative reward. The agent does not know the actions in advance. Exploration and exploitation of known actions is necessary. Explore new actions to furt'},\n",
       " {'slide_index': 16,\n",
       "  'score': 0.25189101696014404,\n",
       "  'preview': 'Graphical models express conditionaldependencies between random variables. Undirected graphical models and Bayesian networks are common models in the literature. Chair of Multimedia Communications and Signal Processing \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0Page 1'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "try:\n",
    "    embedder\n",
    "except NameError:\n",
    "    embedder = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "\n",
    "corpus = [f\"Slide {s['index']}: {s['summary'] or s['text']}\" for s in slide_summaries]\n",
    "embs = embedder.encode(corpus, convert_to_numpy=True, normalize_embeddings=True)\n",
    "\n",
    "def search(query, top_k=5):\n",
    "    q = embedder.encode([query], convert_to_numpy=True, normalize_embeddings=True)\n",
    "    sims = (embs @ q.T).ravel()\n",
    "    top_idx = sims.argsort()[::-1][:top_k]\n",
    "    return [\n",
    "        {\n",
    "            \"slide_index\": slide_summaries[i][\"index\"],\n",
    "            \"score\": float(sims[i]),\n",
    "            \"preview\": (slide_summaries[i][\"summary\"] or slide_summaries[i][\"text\"])[:240]\n",
    "        }\n",
    "        for i in top_idx\n",
    "    ]\n",
    "\n",
    "search(\"Markow-Eigenschaft\")  # or any query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1da7c64e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "id": "wCFs2lmMYr_q",
    "outputId": "c0fc249a-4fe4-44ee-fd50-1570f03ba69a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "repr_error": "Out of range float values are not JSON compliant: nan",
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-d5842037-a671-4e80-9b99-487998fa235f\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>ocr</th>\n",
       "      <th>image_only</th>\n",
       "      <th>preview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d5842037-a671-4e80-9b99-487998fa235f')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-d5842037-a671-4e80-9b99-487998fa235f button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-d5842037-a671-4e80-9b99-487998fa235f');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index, ocr, image_only, preview]\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame([\n",
    "    {\"index\": s[\"index\"], \"ocr\": s[\"ocr_used\"], \"image_only\": s[\"image_only\"],\n",
    "     \"preview\": s[\"text\"][:120].replace(\"\\n\",\" \")}\n",
    "    for s in slides\n",
    "])\n",
    "df[df[\"ocr\"] | df[\"image_only\"]].head(10)  # shows any OCR'd slides\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "331088a2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aWeX6fLNYsCu",
    "outputId": "f1ea32b3-f59c-4324-998f-24c01b52c193"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " mindmap.mmd written to outputs/. Paste it into https://mermaid.live to render.\n"
     ]
    }
   ],
   "source": [
    "import re, os\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "def top_keywords(text, k=3):\n",
    "    words = re.findall(r\"[A-Za-zÄÖÜäöüß][A-Za-zÄÖÜäöüß\\-]{2,}\", text or \"\")\n",
    "    stop = set(\"\"\"\n",
    "der die das ein eine und oder für von mit ohne zu auf an im in aus ist sind war waren sein auch sowie\n",
    "the a an and or for from with without into in on of to is are was were be been being this that these those it its by as at if then else when while not\n",
    "\"\"\".split())\n",
    "    words = [w.lower() for w in words if w.lower() not in stop]\n",
    "    return [w for w,_ in Counter(words).most_common(k)]\n",
    "\n",
    "kw_to_slides = defaultdict(list)\n",
    "for s in slide_summaries:\n",
    "    base = s[\"summary\"] or s[\"text\"]\n",
    "    for kw in top_keywords(base, k=3):\n",
    "        kw_to_slides[kw].append(s[\"index\"])\n",
    "\n",
    "# keep top ~12 keywords\n",
    "top_kws = [kw for kw,_ in Counter(kw_to_slides.keys()).most_common()]\n",
    "top_kws = list(kw_to_slides.keys())[:12]\n",
    "\n",
    "title = os.path.basename(file_path)\n",
    "lines = [\"mindmap\", f\"  root(({title}))\"]\n",
    "for kw in top_kws:\n",
    "    lines.append(f\"    {kw}({kw})\")\n",
    "    for idx in sorted(kw_to_slides[kw])[:6]:\n",
    "        lines.append(f\"      s{idx}([Slide {idx}])\")\n",
    "\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "with open(\"outputs/mindmap.mmd\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(lines))\n",
    "\n",
    "print(\" mindmap.mmd written to outputs/. Paste it into https://mermaid.live to render.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37448074",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TegKI0hOcydx",
    "outputId": "01ca7390-2b17-4b24-89e8-a09dc256040a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flashcards.csv written to outputs/ — total cards: 99\n"
     ]
    }
   ],
   "source": [
    "import csv, re\n",
    "\n",
    "def split_points(text):\n",
    "    bullets = re.findall(r\"(?:^|\\n)[\\-\\•\\*]\\s*(.+)\", text or \"\")\n",
    "    if bullets:\n",
    "        return [b.strip() for b in bullets if len(b.strip()) > 3][:4]\n",
    "    sents = re.split(r\"(?<=[\\.\\!\\?])\\s+\", text or \"\")\n",
    "    return [s for s in sents if len(s.split()) >= 6][:3]\n",
    "\n",
    "def detect_de(text: str) -> bool:\n",
    "    t = (text or \"\").lower()\n",
    "    if any(c in t for c in \"äöüÄÖÜß\"): return True\n",
    "    de_hits = sum(w in t for w in [\"und\",\"der\",\"die\",\"das\",\"ist\",\"nicht\",\"ein\",\"eine\",\"oder\",\"auch\"])\n",
    "    en_hits = sum(w in t for w in [\"and\",\"the\",\"is\",\"are\",\"not\",\"or\",\"also\",\"a\",\"an\"])\n",
    "    return de_hits >= en_hits\n",
    "\n",
    "rows = []\n",
    "for s in slide_summaries:\n",
    "    base = s[\"summary\"] or s[\"text\"]\n",
    "    if not base:\n",
    "        continue\n",
    "    de = detect_de(base)\n",
    "    items = split_points(base)\n",
    "    if items:\n",
    "        for j, it in enumerate(items, 1):\n",
    "            q = (f\"Nenne einen Kerngedanken (Folie {s['index']}, Punkt {j}):\"\n",
    "                 if de else\n",
    "                 f\"Name one key idea (slide {s['index']}, point {j}):\")\n",
    "            rows.append([q, it, f\"ClassMind;{'DE' if de else 'EN'}\"])\n",
    "    else:\n",
    "        q = (f\"Was ist die Kernaussage von Folie {s['index']}?\"\n",
    "             if de else\n",
    "             f\"What is the main idea of slide {s['index']}?\")\n",
    "        rows.append([q, base, f\"ClassMind;{'DE' if de else 'EN'}\"])\n",
    "\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "with open(\"outputs/flashcards.csv\", \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "    w = csv.writer(f); w.writerow([\"Question\",\"Answer\",\"Tags\"]); w.writerows(rows)\n",
    "\n",
    "print(f\"flashcards.csv written to outputs/ — total cards: {len(rows)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea40f76",
   "metadata": {
    "id": "ibH_jIiacyg0"
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "try:\n",
    "    summarizer\n",
    "except NameError:\n",
    "    summarizer = pipeline(\"summarization\", model=\"csebuetnlp/mT5_multilingual_XLSum\", device=-1)\n",
    "\n",
    "def chunk_by_tokens(text, tokenizer, max_tokens=480):\n",
    "    enc = tokenizer(text, return_attention_mask=False, truncation=False)\n",
    "    ids = enc[\"input_ids\"]\n",
    "    return [tokenizer.decode(ids[i:i+max_tokens], skip_special_tokens=True)\n",
    "            for i in range(0, len(ids), max_tokens)]\n",
    "\n",
    "def summarize_long_text(text, target_max=260, target_min=160, max_input_tokens=480):\n",
    "    tok = summarizer.tokenizer\n",
    "    if not text.strip():\n",
    "        return \"\"\n",
    "    parts = chunk_by_tokens(text, tok, max_tokens=max_input_tokens)\n",
    "    partial = [summarizer(p, max_length=160, min_length=60, do_sample=False, truncation=False)[0][\"summary_text\"] for p in parts]\n",
    "    merged = \"\\n\".join(partial)\n",
    "    final = summarizer(merged, max_length=target_max, min_length=target_min, do_sample=False, truncation=False)[0][\"summary_text\"]\n",
    "    return final.strip()\n",
    "\n",
    "full_text = \"\\n\\n\".join(s[\"text\"] for s in slides if s[\"text\"])\n",
    "deck_summary = summarize_long_text(full_text)\n",
    "\n",
    "with open(\"outputs/deck_summary.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(deck_summary)\n",
    "\n",
    "print(\"✅ deck_summary.txt written to outputs/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bac464b",
   "metadata": {
    "id": "hx3pefhBcyj3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33df967c",
   "metadata": {
    "id": "kD-r3qcKcym4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec3f56c",
   "metadata": {
    "id": "_ibZtYgrcyrH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a56248",
   "metadata": {
    "id": "X8qn37uKYsGe"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
